\section{Approach} \label{sec:Approach}

\subsection{Datasets}

Throughout our project, we apply a few datasets and analyze their generated
graphs. The datasets we use are, relatively speaking, orthogonal to each other -
They solve fundamentally different problems. As such, any similarities may be in
response to parameter changes, the network structure, or 'problem-solving'
itself.

Our first benchmark is the MNIST dataset \cite{MNIST Dataset}. This dataset
requires the tools of image recognition and classification, and is popular in
machine learning projects.

From there, we look at the Numenta Anomaly Benchmark dataset \cite{NAB Dataset}.
Anomaly detection is a problem that temporal neural networks generally
specialize in, so we analyze these as well.

Finally, we generate and analyze a network for the NFL Big Data Bowl dataset
\cite{NFL Dataset}. This network would perform prediction for the next 'play'
(e.g. pass or rush) based on the previous play's characteristics.

\subsection{Assumptions}

While we vary a variety of parameters (such as neuron activation function), we
assume that the underlying temporal neurons function as a strong analogue for
biological processes. This assumption allows us to generalize our results to
neural basis of cognition rather than design of artificial neural networks.

\subsection{Analysis}

The focus of analysis is the network generated within the liquid reservoir. This
liquid has nodes of neurons and edges of weighted synapses.

We test the robustness claim of \cite{LSM Constraints} by analyzing the
connectivity of these networks over their growth. We also analyze diameter in
order to understand the 'distance' between neurons in the network (and the
amount of time it takes for a spike to propagate).

\subsection{Research Questions}

Through these network features, and more, we aim to understand the following:

\begin{enumerate}
    \item Why did the network configure itself the way it did?
    \item How do networks of different problems compare to each other?
\end{enumerate}